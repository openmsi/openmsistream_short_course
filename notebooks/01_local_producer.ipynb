{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Producer\n",
    "\n",
    "In this exercise, you'll run a producer on your computer to send some arbitrary files to a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib, logging, importlib\n",
    "from threading import Thread\n",
    "from openmsitoolbox.logging import OpenMSILogger\n",
    "from openmsistream import UploadDataFile, DataFileUploadDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a logger (only needed when running in a Jupyter notebook like this)\n",
    "logger = OpenMSILogger(\"LocalProducer\", filelevel=None)\n",
    "importlib.reload(logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the topic to work with\n",
    "TOPIC_NAME = \"tutorial_data\"\n",
    "\n",
    "# Paths to the config file and the directory holding the test files\n",
    "repo_root_dir = pathlib.Path().resolve().parent\n",
    "CONFIG_FILE_PATH = repo_root_dir / \"config_files\" / \"confluent_cloud_broker.config\"\n",
    "TEST_FILE_DIR = repo_root_dir.parent / \"tutorial_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's just call UploadDataFile for each file in the directory\n",
    "\n",
    "This will start up a producer and send every chunk for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every file in the folder\n",
    "for iuf, upload_file_path in enumerate(TEST_FILE_DIR.rglob(\"*\")):\n",
    "    # Skip any hidden files (like .DS_Store....)\n",
    "    if upload_file_path.is_dir() or upload_file_path.name.startswith(\".\"):\n",
    "        continue\n",
    "    # Create an UploadDataFile and call the function to upload it to the topic\n",
    "    upload_file = UploadDataFile(upload_file_path, rootdir=TEST_FILE_DIR, logger=logger)\n",
    "    upload_file.upload_whole_file(CONFIG_FILE_PATH, TOPIC_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next let's watch for new files in a folder using a DataFileUploadDirectory\n",
    "\n",
    "You could run this as an interactive program from the command line, and type a command to shut it down when you wanted to, but here we'll run it in a separate thread from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_task(upload_directory, *args, **kwargs):\n",
    "    \"\"\"Run \"upload_files_as_added\" for a given DataFileUploadDirectory, and log a message\n",
    "    when it gets shut down\n",
    "\n",
    "    Args:\n",
    "        upload_directory (DataFileUploadDirectory): the DataFileUploadDirectory to run\n",
    "        args (list): passed through to \"upload_files_as_added\"\n",
    "        kwargs (dict): passed through to \"upload_files_as_added\"\n",
    "    \"\"\"\n",
    "    # This call to \"upload_files_as_added\" waits until the program is shut down\n",
    "    uploaded_filepaths = upload_directory.upload_files_as_added(*args, **kwargs)\n",
    "    msg = (\n",
    "        f\"The following files were uploaded:\\n\\t\"\n",
    "    )\n",
    "    msg += \"\\n\\t\".join([str(fp) for fp in uploaded_filepaths])\n",
    "    upload_directory.logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFileUploadDirectory\n",
    "dfud = DataFileUploadDirectory(TEST_FILE_DIR, CONFIG_FILE_PATH, logger=logger)\n",
    "# Start running its \"upload_files_as_added\" function in a separate thread\n",
    "upload_thread = Thread(\n",
    "    target=upload_task,\n",
    "    args=(\n",
    "        dfud,\n",
    "        TOPIC_NAME,\n",
    "    ),\n",
    ")\n",
    "upload_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the above cell running, any files you move into the watched directory will be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually shut down the upload directory (if running from the command line this would\n",
    "# be like typing \"q\" in the Terminal window)\n",
    "dfud.control_command_queue.put(\"q\")\n",
    "upload_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensorpush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
