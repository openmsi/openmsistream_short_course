{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib, importlib, logging, datetime, json, platform\n",
    "from threading import Thread\n",
    "from openmsitoolbox.logging import OpenMSILogger\n",
    "from openmsistream import DataFileDownloadDirectory, MetadataJSONReproducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'logging' from '/usr/local/anaconda3/envs/sensorpush/lib/python3.9/logging/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure a logger (only needed when running in a Jupyter notebook like this)\n",
    "logger = OpenMSILogger(\"OpenMSIConsumers\", filelevel=None)\n",
    "importlib.reload(logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the topic to consume files from\n",
    "CONSUMER_TOPIC_NAME = \"openmsistream_tutorial_data\"\n",
    "\n",
    "# Path to the root directory of this repo\n",
    "repo_root_dir = pathlib.Path().resolve().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consuming to the local filesystem\n",
    "\n",
    "Read chunks of files from the topic and write them to a location on your local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_task(download_directory):\n",
    "    \"\"\"Run \"reconstruct\" for a given DataFileDownloadDirectory, and log some messages\n",
    "    when it gets shut down\n",
    "\n",
    "    Args:\n",
    "        download_directory (DataFileDownloadDirectory): the DataFileDownloadDirectory to run\n",
    "    \"\"\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # This call to \"upload_files_as_added\" waits until the program is shut down\n",
    "    (\n",
    "        n_read,\n",
    "        n_processed,\n",
    "        n_complete_files,\n",
    "        complete_filepaths,\n",
    "    ) = download_directory.reconstruct()\n",
    "    download_directory.close()\n",
    "    end_time = datetime.datetime.now()\n",
    "    ts_format = \"%m-%d-%Y %H:%M:%S\"\n",
    "    start_stamp = start_time.strftime(ts_format)\n",
    "    end_stamp = end_time.strftime(ts_format)\n",
    "    # Create a log a message stating the files that were downloaded during the run\n",
    "    msg = f\"{n_read} total messages were consumed\"\n",
    "    if len(complete_filepaths) > 0:\n",
    "        msg += (\n",
    "            f\", {n_processed} messages were successfully processed, and \"\n",
    "            f'{n_complete_files} file{\" was\" if n_complete_files==1 else \"s were\"} '\n",
    "            \"successfully reconstructed\"\n",
    "        )\n",
    "    else:\n",
    "        msg += f\" and {n_processed} messages were successfully processed\"\n",
    "    msg += (\n",
    "        f\" from {start_stamp} to {end_stamp}\\n\"\n",
    "        f\"Most recent completed files (up to {download_directory.N_RECENT_FILES}):\\n\\t\"\n",
    "    )\n",
    "    msg += \"\\n\\t\".join([str(filepath) for filepath in complete_filepaths])\n",
    "    download_directory.logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the config file and the directory holding the test files\n",
    "CONFIG_FILE_PATH = repo_root_dir / \"config_files\" / \"confluent_cloud_broker.config\"\n",
    "TEST_RECO_DIR = repo_root_dir.parent / \"reconstructed_test_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[OpenMSIConsumers 2023-12-18 17:30:29] Will reconstruct files from messages in the openmsistream_tutorial_data topic using 2 threads\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFileDownloadDirectory\n",
    "dfdd = DataFileDownloadDirectory(\n",
    "    TEST_RECO_DIR,\n",
    "    CONFIG_FILE_PATH,\n",
    "    CONSUMER_TOPIC_NAME,\n",
    "    logger=logger,\n",
    ")\n",
    "# Start running its \"reconstruct\" function in a separate thread\n",
    "download_thread = Thread(\n",
    "    target=download_task,\n",
    "    args=(dfdd,),\n",
    ")\n",
    "download_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While the above cell is running, if any new files get produced to the topic you'll see them reconstructed on your file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[OpenMSIConsumers 2023-12-18 17:30:37] 6 total messages were consumed, 6 messages were successfully processed, and 6 files were successfully reconstructed from 12-18-2023 17:30:29 to 12-18-2023 17:30:37\n",
      "Most recent completed files (up to 50):\n",
      "\ttesting_1.txt\n",
      "\tnested_dir/testing_1 copy.txt\n",
      "\ttesting_2.txt\n",
      "\tnested_dir/testing_3.txt\n",
      "\tnested_dir/testing_2 copy.txt\n",
      "\ttesting_3 copy.txt\n"
     ]
    }
   ],
   "source": [
    "# Manually shut down the download directory (if running from the command line this would\n",
    "# be like typing \"q\" in the Terminal window)\n",
    "dfdd.control_command_queue.put(\"q\")\n",
    "download_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting some simple metadata and producing to another topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMetadataReproducer(MetadataJSONReproducer):\n",
    "    \"\"\"Reads DataFile messages from one topic and produces a JSON-formatted string with\n",
    "    some very simple metadata to another topic\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_metadata_dict_for_file(self, datafile):\n",
    "        \"\"\"See docs here:\n",
    "        https://openmsistream.readthedocs.io/en/latest/user_info/base_classes/metadata_json_reproducer.html\n",
    "        for more information on writing custom MetadataJSONReproducers\n",
    "        \"\"\"\n",
    "        # create a dictionary of very simple info about the consumed file\n",
    "        metadata_dict = {\n",
    "            \"relative_filepath\": datafile.relative_filepath.as_posix(),\n",
    "            \"size_in_bytes\": len(datafile.bytestring),\n",
    "            \"consumed_from\": self.consumer_topic_name,\n",
    "            \"consumed_on\": platform.system(),\n",
    "        }\n",
    "        # add a timestamp\n",
    "        metadata_dict[\"metadata_extracted_at\"] = datetime.datetime.now().strftime(\n",
    "            \"%m/%d/%Y, %H:%M:%S\"\n",
    "        )\n",
    "        # return the dictionary of metadata\n",
    "        self.logger.debug(\n",
    "            f\"Producing JSON metadata message: {json.dumps(metadata_dict)}\"\n",
    "        )\n",
    "        return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducer_task(reproducer):\n",
    "    \"\"\"Run \"produce_processing_results_for_files_as_read\" for a given\n",
    "    MetadataJSONReproducer, and log some messages when it gets shut down\n",
    "\n",
    "    Args:\n",
    "        reproducer (MetadataJSONReproducer): the MetadataJSONReproducer to run\n",
    "    \"\"\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # This call to \"produce_processing_results_for_files_as_read\" hangs until the program\n",
    "    # is shut down\n",
    "    (\n",
    "        n_m_r, # number of messages read\n",
    "        n_m_p, # number of messages processed\n",
    "        n_f_r, # number of files read\n",
    "        n_f_mp, # number of files that had metadata produced\n",
    "        m_p_fps, # paths to files that had metadata produced (up to 50)\n",
    "    ) = reproducer.produce_processing_results_for_files_as_read()\n",
    "    reproducer.close()\n",
    "    end_time = datetime.datetime.now()\n",
    "    ts_format = \"%m-%d-%Y %H:%M:%S\"\n",
    "    start_stamp = start_time.strftime(ts_format)\n",
    "    end_stamp = end_time.strftime(ts_format)\n",
    "    # Create a log a message stating the files that were processed during the run\n",
    "    msg = \"\"\n",
    "    if n_m_r > 0:\n",
    "        msg += f'{n_m_r} total message{\"s were\" if n_m_r!=1 else \" was\"} consumed, '\n",
    "    if n_m_p > 0:\n",
    "        msg += f'{n_m_p} message{\"s were\" if n_m_p!=1 else \" was\"} successfully processed, '\n",
    "    if n_f_r > 0:\n",
    "        msg += f'{n_f_r} file{\"s were\" if n_f_r!=1 else \" was\"} fully read, '\n",
    "    if n_f_mp > 0:\n",
    "        msg += (\n",
    "            f'{n_f_mp} file{\"s\" if n_f_mp!=1 else \"\"} had json metadata produced '\n",
    "            f'to the \"{reproducer.producer_topic_name}\" topic from {start_stamp} '\n",
    "            f\"to {end_stamp}. Up to {reproducer.N_RECENT_FILES} most recent:\\n\\t\"\n",
    "        )\n",
    "    msg += \"\\n\\t\".join([str(fp) for fp in m_p_fps])\n",
    "    reproducer.logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the config file to use for the Reproducer\n",
    "REPRODUCER_CONFIG_FILE_PATH = (\n",
    "    repo_root_dir / \"config_files\" / \"confluent_cloud_broker_for_reproducer.config\"\n",
    ")\n",
    "\n",
    "# Path to the directory to store the Reproducer registry files\n",
    "REPRODUCER_OUTPUT_DIR = repo_root_dir.parent / \"SimpleMetadataReproducer_output\"\n",
    "\n",
    "# Name of the topic to produce the metadata messages to\n",
    "PRODUCER_TOPIC_NAME = \"openmsistream_tutorial_metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[OpenMSIConsumers 2023-12-18 17:30:46] Log files and output will be in /Users/margareteminizer/Desktop/dmref_materials_project/openmsistream_short_course/SimpleMetadataReproducer_output\n",
      "[OpenMSIConsumers 2023-12-18 17:30:46] Will process files from messages in the openmsistream_tutorial_data topic using 2 threads and produce their processing results to the openmsistream_tutorial_metadata topic using 1 thread\n"
     ]
    }
   ],
   "source": [
    "# Create the MetadataReproducer\n",
    "smdr = SimpleMetadataReproducer(\n",
    "    REPRODUCER_CONFIG_FILE_PATH,\n",
    "    CONSUMER_TOPIC_NAME,\n",
    "    PRODUCER_TOPIC_NAME,\n",
    "    output_dir=REPRODUCER_OUTPUT_DIR,\n",
    "    logger=logger,\n",
    ")\n",
    "# Start running its \"reconstruct\" function in a separate thread\n",
    "reproducer_thread = Thread(\n",
    "    target=reproducer_task,\n",
    "    args=(smdr,),\n",
    ")\n",
    "reproducer_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After you start the above cell running, you should see new messages added to the producer topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[OpenMSIConsumers 2023-12-18 17:30:55] Will quit after all currently enqueued messages are received.\n",
      "[OpenMSIConsumers 2023-12-18 17:30:55] 6 total messages were consumed, 6 messages were successfully processed, 6 files were fully read, 6 files had json metadata produced to the \"openmsistream_tutorial_metadata\" topic from 12-18-2023 17:30:46 to 12-18-2023 17:30:55. Up to 50 most recent:\n",
      "\tnested_dir/testing_1 copy.txt\n",
      "\ttesting_1.txt\n",
      "\ttesting_2.txt\n",
      "\tnested_dir/testing_2 copy.txt\n",
      "\tnested_dir/testing_3.txt\n",
      "\ttesting_3 copy.txt\n"
     ]
    }
   ],
   "source": [
    "# Manually shut down the reproducer (if running from the command line this would\n",
    "# be like typing \"q\" in the Terminal window)\n",
    "smdr.control_command_queue.put(\"q\")\n",
    "reproducer_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensorpush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
